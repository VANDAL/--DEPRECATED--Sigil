
Sigil is a Valgrind tool written to instrument bytes of dataflow between software functions. 
Sigil captures and classifies bytes of communication into multiple categories. The categories can be "unique"(first time transfer) or "non-unique"(repeated transfers) communication, and "input/output" or "local" communication.
Communication classification attempts to extract true inputs and outputs of a software function from observing memory transactions.

The tool is implemented as a run-time profiler and works on the application binary directly to produce platform-independent data. 
It does not need any source code changes or any prior knowledge of the application. Platform-independent data, is not tied down to any specific architecture, but is a property of the application itself.
As a result, data generated on any architecture and any number of times should result in the same output data. 

In its current form, Sigil sits on top of the Callgrind tool that comes with the Valgrind framework.
The Callgrind source is modified minmally to insert calls to the Sigil tool at the appropriate points. Furthermore, Callgrind was also modified to measure integer and floating point operations. 
For a full list of changes, see "README_CHANGES" in the callgrind folder. Please see the Valgrind readme to get an user-level understanding of both Valgrind and Callgrind.
The Sigil implementation is described at the end of this README.




**********************************************************
Building and installing Sigil

The tool can be found at https://github.com/snilakan/Sigil and comes with this file.
Sigil has been tested on Intel Xeon E5620-based machines, running the RedHat Enterprise Linux 5 operating system.
The tool can be compiled by following the instructions to make/install Valgrind and its suite of tools.
Simply navigate into the directory for Valgrind (accompanying folder) and follow the README.
The current version of Sigil is built into valgrind-3.7 and needs no separate build process.
When the Callgrind tool is built, Sigil gets built automatically.

To summarize the Valgrind build documentation on Linux, it simply involves the usual 'make' and 'make install' in the Valgrind directory.
If you prefer not to 'make install' Valgrind, you can build Valgrind using just the 'make' and run it in place using Valgrind's in-place script. 
See the "README_DEVELOPERS" document in the Valgrind folder for further clarification.

We recommend running all the sanity checks that come pre-packaged with Callgrind.
After building Valgrind, navigate to the Callgrind folder and run 'make check'.
This will build all the regression tests/sanity checks for Callgrind and Sigil.
If any of these sanity checks fail, Sigil cannot run on that system.

If Callgrind checks fail, please see the Valgrind notes/documentation and if necessary, lookup/mail to the Valgrind mailing list.
If the Callgrind checks complete, but Sigil checks fail, please contact us (http://dpac.ece.drexel.edu/current-research-projects/sigil/).

**********************************************************





**********************************************************
How do I run the tool?

Sigil can be run as part of the Callgrind tool. To understand details of how to run Callgrind, please see Callgrind documentation (http://valgrind.org/docs/manual/cl-manual.html).
The documentation should also contain a list of command line options that can be given to Callgrind.
Callgrind's command line options have been extended to i) enable Sigil and ii) give Sigil command line options
Sigil should be compatible with any and all of Callgrind's own command line options as well.

The only (highly) recommended modification to the application you wish to profile, is compiling it with debugging symbols. i.e. -g.
This is recommended for stock Callgrind as well.

Sigil is invoked as follows:
valgrind --tool=callgrind <Callgrind command line options> --sigil-tool=yes <Sigil command line options> <user program>

If you prefered not to 'make install' Valgrind, and built Valgrind using just the 'make', you can run it in place using Valgrind's in-place script. 
In such a case, the command takes the form:
<build location>/vg-in-place --tool=callgrind <Callgrind command line options> --sigil-tool=yes <Sigil command line options> <user program>

As with the Callgrind tool itself, Sigil dumps its data in the folder where the command was run. Please see the list of supported options and the NOTES
on the restrictions of their use.


***
Here are a list of Callgrind options that are *required* and necessary to run Sigil usefully.

--tool=callgrind - Tells Valgrind to run the callgrind tool. 

--cache-sim=yes - Tells callgrind to run a cache simulation. Please see Callgrind notes for more information on this option. 
In some systems, a manual number may need to be entered for the caches being simulated.
(These numbers will make no difference to Sigil results but may be necesary for Callgrind's cache simulation to function correctly)

--separate-callers=<number of callers>. - Sigil needs full calling contexts to create unique nodes for functions based on their calling context. 
So this option needs to be at least large enough to support the branch of a calltree with the largest depth (including all functions called before 'main' and after 'exit').
If an application has very large depth in the calltree, the memory needed by Callgrind structures may become quite large as well.
***



***
Here are the list of command-line arguments to Sigil and what they mean. Please also see the NOTES below:

--sigil-tool - Enable sigil tool or run stock callgrind? Options are "yes" or "no". Default: "no" which runs just the stock Callgrind.

--drw-func - Enable function-level profiling? If enabled, this option profiles communication between functions. This was the first envisioned use case for Sigil.
Options are "yes" or "no" Default: "no". "no" runs thread-level profiling and gives producer-consumer information between threads only. 
For single-threaded user program runs, keeping this at "no" will provide no useful information.

--drw-syscalltracing - Enable tracing of syscalls during profiling? Sigil will try to track dependencies through system calls as well. 
Fidelity of results are not currently guaranteed but it should work. Options are "yes" or "no". Default: "no"
Note: In the current implementation, Sigil treats all memory related system calls including mmaps and brks as LD/STs to simplify implementation. 
This causes increased memory usage. We are working on a way to improve the implementation.

--drw-smlimit - Limit on the size of shadow memory (in MB). Sigil tries to reclaim space when the shadow memory exceeds this limit. 
Depending on the application and your machine, the recommended limit is anywhere from 5GB - 20GB. default is "20000" which is 20GB.

--drw-debug - Print memory usage information? Options are "yes" or "no". Default: "no" which does not print any debug information. 
Note: Valgrind's "--profile-heap=yes" options allows much more detailed debugging information on memory usage.

--drw-events - Gather events during profiling? Capturing events allows reconstruction of dependencies over the program run. 
Costs significantly more memory during profiling. default is "no". Options are "yes" or "no"

--drw-datareuse - Enable examining of byte-level reuse in profiling? default is "no". Options are "yes" or "no"


NOTES: 
Currently, we do not recommended using the "--drw-events" and "--drw-datareuse" options as they have not been tested more recently with the full suite of benchmarks. 
They are not guaranteed to work in this release, so please use at your own risk.
Currently, it is also not possible to use all combinations of the above command line options. 
Especially, memory intensive options should not be used together. 
For example, "--drw-events" and "--drw-datareuse" cannot and should not be used together.
Since "--drw-syscalltracing" also adds memory overhead, use sparingly in combination with the other options.
Finally, it is not recommended to turn on function-level profiling for multi-threaded programs, as that could be very memory intensive and may not necessarily provide useful information.
***


If you prefer not to 'make install' Valgrind, you can build Valgrind using just the 'make' and run it in place using Valgrind's in-place script. 
In such a case, the command takes the form:
<build location>/vg-in-place --tool=callgrind <Callgrind command line options> --sigil-tool=yes <Sigil command line options> <user program>

This produces an output file(s) named sigil.totals.out-<thread_number> in the folder where it was invoked. 

A Python post-processing script is available to run through the results and present them in a more readable format. 
This is found in the accompanying 'postprocessing' folder. The 'postprocessing' script comes with its own README.
It is run on the sigil output file. If given a callgrind output file for the same run, it uses a simple demonstrative algorithm to find the hotspots.
This is discussed in detail in the publication (http://ieeexplore.ieee.org/xpl/articleDetails.jsp?reload=true&arnumber=6704685).

The post processing is run as follows:
Invocation: aggregate_costs_gran.py <inputfile> <printcallees?=yes|no> <percentofinst=0-100>
The post-processing script currently prints inclusive costs of each function in each unique context, in a calltree fashion similar to callgrind itself.
**********************************************************




**********************************************************
Example of tool run:

valgrind --tool=callgrind --cache-sim=yes --separate-callers=100 --sigil-tool=yes --drw-func=yes --drw-syscalltracing=no ls -l
This should produce a callgrind output file and sigil output file without any errors. 
The 'ls -l' can be replaced with your own program and it should work.
**********************************************************




**********************************************************
What programs can be profiled by the tool? (Restrictions/Known issues)

As the tool incurs slowdown already, some restrictions were placed purposefully on the user program, 
so that writing optimized code would be somewhat easier and the memory behavior of the tool is more determinate.
The restrictions are as follows:

1. Each function name must be unique across the application. The user program must not have overloaded function. This can cause the post-processing script to get confused.
We are working on a solution to this problem.
2. The maximum depth of the calltree in the user program (after main) must not exceed the <number> - 10, specified in --separate-callers=<number> while invoking the tool. 
The default for <number> specified earlier was 100, but it can simply be the maximum depth of the calltree in the user program + 10. 
The additional 10 is just a buffer for the functions before main() and after exit().
3. The number of callees for each function in the user program should at most be 1000. (These are hardcoded)
4. The number of functions in the program must not exceed 10,000. (Also hardcoded)
5. Sigil cannot handle address values above 256G currently. 
6. Applications with a large memory footprint can cause Sigil to exceed memory bounds set by Valgrind or the system. 
If such an error is encountered, we recommend running with smaller input sets.
7. Applications with very large call depth can also cause Sigil to exceed memory bounds. Currently, there is no workaround for this, but we are working on a long term solution that could mean tighter integration with Callgrind.

Runs from some popular benchmark suites are available on the website. Please read the next sub-section for details.
Sigil's slowdown is exponentially related the size of the user program and the data given as input to it.

**********************************************************




**********************************************************
How has this tool been tested?

Sigil has been tested on Intel Xeon E5620-based machines, running the RedHat Enterprise Linux 5 operating system.
We ran the SPEC2006 and PARSEC suite (serial version) of benchmarks under Sigil and analyzed the data. 
The analysis was reported and discussed in the publication (http://ieeexplore.ieee.org/xpl/articleDetails.jsp?reload=true&arnumber=6704685). 

You can find data for SPEC and PARSEC benchmarks on Drexel's Power-Aware Computing Lab website (http://dpac.ece.drexel.edu/current-research-projects/sigil/)

**********************************************************





***********************************************************
Information provided by this tool:
Understanding the raw data provided by Sigil:

At the end of a user program run, Sigil will produce a data file that resides in the same folder.
This file has some simple header information and is then divided into two sections beyond that. 

The first section called the "TREE DUMP" prints the serialized calltree nodes with a specific numbering system.
Each function gets a unique number that matches what Callgrind gives the function (called the "function number").
A function also gets a unique number for every context that it is called in (called the "func_inst number").
Thus every node in the tree is identified uniquely by two numbers.
The "TREE DUMP" is only used for reconstructing the links of the tree in post-processing, but does not have any information on produced/consumed bytes.
Each node is specified on a separate line. The serialization algorithm (follows the DWARF Debugging standard) defines the order in which nodes appear in this section.

The next section, called "DATA DUMP" lists the functions without guaranteeing a particular order. 
This section contains a block of data for each node described above. Blocks are separated by two blank lines (newline characters).
The first line in this block is an identifier/summary line characterized by the "*" printed in the line.
Again, each node is identified uniquely with the function number, funcinst number and now also carries a name. 

The block of data also contains separate lines for information on all the nodes that consumed from this node and all nodes that this node consumed from.
These lists are two separate sub-blocks separated by a blank line. The first sub-block (immediately following the identifier line) lists nodes that this particular node consumed from.
The second sub-block (immediately following the identifier line) lists the nodes that consumed data from this particular node.

Thread numbers have also been added as an identifier since Sigil was expanded to support multiple threads.

This tool will give you the following metric costs associated with each node under separate columns:

1. INSTRS: Total instructions spent in the node. Specified only for identifier line of the block.
2. IOPS: Total Integer Operations spent in the node. Specified only for identifier line of the block.
3. FLOPS: Total Floating-Point Operations spent in the node. Specified only for identifier line of the block.
4. IPCOMM: The number of bytes read by the node as input from other functions that produced the data. 
On the individual sub-block lines, numbers in this column refer to the bytes read from the node represented by that line.
On the identifier line, this column entry represents the sum total of bytes read from the nodes in the input sub-block.
5. OPCOMM: The number of bytes produced by this function and read by other functions.
On the individual sub-block lines, numbers in this column refer to the produced bytes read by the node represented by that line.
On the identifier line, this column entry represents the sum total of bytes sent to all the consumers in the output sub-block.
6. IPCOMM_UNIQUE The same as 4., except discounting bytes that were already read by this node. 
This column entry on a sub-block line represents the bytes read from the node represented by that line, but when any byte of data is transferred more than once, it is counted only as a single byte transfer.
The sum total of all entries in the sub-block is represented as a total on the identifier line.
7. OPCOMM_UNIQUE The same as 3., except, once again, when any byte of data is transferred more than once, it is counted only as a single byte transfer.

The aim of capturing these metrics is to help determine which functions show behavior similar to hotspots ( can potentially be accelerated in hardware ).
The number of INSTRUCTIONS in a function represent the actual work that is done by the function in terms of computation. 
The IPCOMM and OPCOMM metrics represent the work done in fetching and sending data to the function from outside. 
In essence, a higher Computation/Communication ratio is indicative of a good candidate for hardware acceleration.
The justification for capturing 6. and 7. is as follows:
While Computation/Communication is an important metric, an accelerator for a function should not incur the overhead of communicating the same data repeatedly, 
as it should buffer fetched data and reuse it within the function (depending on buffering limits).
Metrics 6 and 7 capture the true input and output data needed by the function to finish its task.
A good hardware acceleration mechanism should have a high Computation to Unique-Communication ratio.
**********************************************************






***********************************************************
Implementation details:

TODO: Expand this section
Sigil uses a Shadow Memory implementation to identify and store the producer and consumer functions for each byte of data.
It does so byt shadowing memory locations and hold shadow objects for each memory location. 
The shadow objects store the last writer and last reader of that memory address.
The Shadow Memory implementation is the same one used in the Memcheck tool that Valgrind was originally authored for.
The advantage to this implementation is memory efficiency and performance.

Sigil also holds independent data structures for functions seen in every unique calling context.
There are multiple nodes for each function, based on the context of the call. 
Thus if a function is called in two different contexts, two separate nodes are created so that the cost for each context may be uniquely determined. 
These nodes are linked to one another to represent the calltree of the program.
Finally, Sigil also has data structures linked to each function that hold the list of consumers and the bytes they consumed. 

For every LD/ST encountered in the user program, Sigil is called, to update its data structures.
Sigil incurs a manageable slowdown and needs more memory than Callgrind due to its heavy shadow objects.
For more detailed information, please refer the publication for now[1].

[1] "Platform-independent analysis of function-level communication in workloads" http://ieeexplore.ieee.org/xpl/articleDetails.jsp?reload=true&arnumber=6704685

***********************************************************

Happy Sigilling!
